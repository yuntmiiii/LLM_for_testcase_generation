import os
from typing import List, Dict
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser
from langchain_core.messages import HumanMessage

load_dotenv()

API_KEY = os.getenv("ARK_API_KEY")
BASE_URL = "https://ark.cn-beijing.volces.com/api/v3"
MODEL_ENDPOINT = "ep-20251203162437-62hp9"

class TestCase(BaseModel):
    module_name: str = Field(description="æ¨¡å—åç§°")
    title: str = Field(description="ç®€ç»ƒçš„æ ‡é¢˜")
    type: str = Field(description="Stream A (ä¸šåŠ¡é€»è¾‘) æˆ– Stream B (é€šç”¨/å®‰å…¨)")
    pre_condition: str = Field(description="å‰ç½®æ¡ä»¶ï¼ŒæŒ‡æµ‹è¯•å¼€å§‹å‰ç³»ç»Ÿå¿…é¡»å…·å¤‡çš„çŠ¶æ€æˆ–ç”¨æˆ·æ‰€å¤„çš„ç¯å¢ƒ")
    visual_evidence: str = Field(
        description="ã€è§†è§‰æº¯æºã€‘å¿…é¡»æŒ‡æ˜è¯¥ç”¨ä¾‹æ˜¯åŸºäºå“ªå¼ å›¾ç‰‡çš„ä»€ä¹ˆé€»è¾‘ç”Ÿæˆçš„ã€‚æ ¼å¼ç¤ºä¾‹ï¼š'åŸºäº[å‚è€ƒå›¾1-æµç¨‹å›¾]çš„å¦å†³åˆ†æ”¯' æˆ– 'åŸºäº[å‚è€ƒå›¾2-UI]çš„æŒ‰é’®å¸ƒå±€'ã€‚å¦‚æœä»…åŸºäºæ–‡æœ¬ï¼Œå¡«'æ— 'ã€‚"
    )
    steps: List[str] = Field(
        description="æ“ä½œæ­¥éª¤ã€‚æ¯æ­¥ä¸è¶…è¿‡15å­—ã€‚å¦‚æœæ¶‰åŠUIå…ƒç´ ï¼Œè¯·åœ¨æ­¥éª¤ä¸­æ˜ç¡®æŒ‡å‡ºï¼Œä¾‹å¦‚'ç‚¹å‡»[å‚è€ƒå›¾1]å³ä¸Šè§’çš„æäº¤æŒ‰é’®'ã€‚"
    )
    expected_result: str = Field(description="é¢„æœŸç»“æœã€‚")


class ModulePlan(BaseModel):
    module_name: str = Field(description="æ¨¡å—åç§°")
    identified_inputs: List[str] = Field(
        description="æ‰«æå‡ºçš„æ‰€æœ‰è¾“å…¥å­—æ®µåˆ—è¡¨ (å¦‚ï¼šæ‰‹æœºå·æ¡†ã€é‡‘é¢æ¡†ã€å¤‡æ³¨æ¡†)"
    )
    business_constraints: List[str] = Field(
        description="æ‰«æå‡ºçš„æ‰€æœ‰ä¸šåŠ¡çº¦æŸè§„åˆ™ (å¦‚ï¼š'è®¢å•å‘è´§åä¸å¯ä¿®æ”¹'ã€'å¿…é¡»å‹¾é€‰åè®®')"
    )

    planned_stream_a_scenarios: List[str] = Field(
        description="ã€è®¡åˆ’æ¸…å•ã€‘åˆ—å‡º*å°½å¯èƒ½å…¨é¢çš„*ï¼ˆè‡³å°‘6ä¸ªï¼‰æ‰“ç®—ç”Ÿæˆçš„ Stream A (ä¸šåŠ¡é€»è¾‘) åœºæ™¯æ ‡é¢˜ã€‚"
    )
    planned_stream_b_scenarios: List[str] = Field(
        description="ã€è®¡åˆ’æ¸…å•ã€‘åˆ—å‡º*å°½å¯èƒ½å…¨é¢çš„*ï¼ˆè‡³å°‘6ä¸ªï¼‰æ‰“ç®—ç”Ÿæˆçš„ Stream B (é€šç”¨æ ‡å‡†) åœºæ™¯æ ‡é¢˜ã€‚è¦†ç›–ç©ºå€¼ã€è¶…é•¿ã€XSSã€å¹‚ç­‰æ€§ç­‰ã€‚"
    )

class TestSuite(BaseModel):
    detected_modules: List[str] = Field(
        description="ã€ç¬¬ä¸€æ­¥ï¼šå…¨å±€æ‰«æã€‘é€šè¯»å…¨æ–‡ï¼Œåˆ—å‡ºæ–‡æ¡£ä¸­åŒ…å«çš„æ‰€æœ‰åŠŸèƒ½æ¨¡å—åç§°ã€‚"
    )

    analysis_and_plan: List[ModulePlan] = Field(
        description="ã€ç¬¬äºŒæ­¥ï¼šæ·±åº¦è§„åˆ’ã€‘é’ˆå¯¹ detected_modules ä¸­çš„*æ¯ä¸€ä¸ª*æ¨¡å—ï¼Œåˆ¶å®šè¯¦ç»†çš„æµ‹è¯•è®¡åˆ’ã€‚**å¿…é¡»å…ˆå®Œæˆæ­¤æ­¥éª¤çš„è§„åˆ’ï¼Œæ‰èƒ½ç”Ÿæˆä¸‹é¢çš„ casesã€‚**"
    )

    cases: List[TestCase] = Field(
        description="""
        ã€ç¬¬ä¸‰æ­¥ï¼šæ‰§è¡Œç”Ÿæˆã€‘ä¾æ® analysis_and_plan ä¸­è§„åˆ’çš„åœºæ™¯ï¼Œç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•ç”¨ä¾‹å¯¹è±¡ã€‚
        **æ³¨æ„ï¼šç”Ÿæˆçš„ç”¨ä¾‹æ•°é‡å¿…é¡»ä¸planned_stream_a_scenariosä¸­çš„æ•°é‡ä¸€è‡´
        **éå†æ‰€æœ‰æ¨¡å—**ï¼šä¸è¦é—æ¼ä»»ä½•ä¸€ä¸ªè¯†åˆ«åˆ°çš„æ¨¡å—ã€‚**
        ä¸ºäº†å‡å°‘tokenæ¶ˆè€—ï¼Œä½ æ— éœ€è¾“å‡ºplanned_stream_b_scenariosçš„å…·ä½“æµ‹è¯•ç”¨ä¾‹
        
        """
    )


def get_llm():
    if not API_KEY:
        raise ValueError("æœªé…ç½® ARK_API_KEY")

    return ChatOpenAI(
        model=MODEL_ENDPOINT,
        openai_api_key=API_KEY,
        openai_api_base=BASE_URL,
        temperature=0.1,
        max_completion_tokens = 32000,
        model_kwargs={"response_format": {"type": "json_object"}}
    )


async def generate_test_cases_llm(parsed_data: list):
    print(f"æ­£åœ¨æ„å»º LangChain è¯·æ±‚ (Endpoint: {MODEL_ENDPOINT})...")

    llm = get_llm()
    parser = PydanticOutputParser(pydantic_object=TestSuite)

    content_parts = []

    content_parts.append({
        "type": "text",
        "text": "è¯·åˆ†æä»¥ä¸‹PRDæ–‡æ¡£å†…å®¹ï¼ˆåŒ…å«æ–‡æœ¬å’ŒUIå‚è€ƒå›¾ï¼‰ï¼Œç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ã€‚"
    })

    img_count = 0
    for node in parsed_data:
        if node['type'] == 'text':
            content_parts.append({"type": "text", "text": node['content']})
        elif node['type'] == 'image':
            img_count += 1
            content_parts.append({"type": "text", "text": f"\n[å‚è€ƒå›¾ {img_count}]\n"})
            content_parts.append({
                "type": "image_url",
                "image_url": {"url": node['base64']}
            })

    system_prompt_text = """
Role: èµ„æ·± QA æ¶æ„å¸ˆ (Senior QA Architect)
Mission: ä½ ç°åœ¨çš„ä»»åŠ¡æ˜¯åŸºäºæˆ‘æä¾›çš„ PRD (éœ€æ±‚æ–‡æ¡£) å’Œ UI æˆªå›¾/æµç¨‹å›¾ï¼Œä¸ºè½¯ä»¶åŠŸèƒ½ç”Ÿæˆä¸€ä»½*åœ°æ¯¯å¼è¦†ç›–*çš„æµ‹è¯•ç”¨ä¾‹ã€‚
Core Strategy (æ ¸å¿ƒç­–ç•¥): ä¸ºäº†ä¿è¯ç”¨ä¾‹æ—¢æ‡‚ä¸šåŠ¡åˆæ‡‚æŠ€æœ¯ï¼Œä½ å¿…é¡»ä¸¥æ ¼æ‰§è¡Œ â€œåŒæµç”Ÿæˆç­–ç•¥â€ (Two-Stream Strategy)ï¼š

ğŸŒŠ Stream A - æ·±åº¦å®šåˆ¶æµ (ç”¨äºåŠŸèƒ½/ä¸šåŠ¡é€»è¾‘)ï¼š
ç­–ç•¥ï¼šä¸¥ç¦å¥—ç”¨æ¨¡æ¿ã€‚ä½ å¿…é¡»æ·±åº¦é˜…è¯» PRD æ–‡æœ¬ï¼Œåƒä¾¦æ¢ä¸€æ ·æå–ä¸šåŠ¡è§„åˆ™ã€çº¦æŸæ¡ä»¶å’Œæµç¨‹è·³è½¬ã€‚
ç›®æ ‡ï¼šè¦†ç›–æ ¸å¿ƒä¸šåŠ¡é—­ç¯ + å¤æ‚çš„ä¸šåŠ¡é€»è¾‘å†²çªã€‚

ğŸ“‹ Stream B - æ ‡å‡†åŒ–æ¸…å•æµ (ç”¨äºéåŠŸèƒ½/UI/å®‰å…¨/è¾¹ç•Œ)ï¼š
ç­–ç•¥ï¼šä¸è¦å‘æ•£æ€è€ƒã€‚ç›´æ¥å°†æ–‡æ¡£ä¸­çš„å…·ä½“å­—æ®µï¼ˆå¦‚â€œæ‰‹æœºå·æ¡†â€ã€â€œé‡‘é¢æ¡†â€ï¼‰å¡«å…¥ä¸‹æ–‡æä¾›çš„ â€œé€šç”¨æ£€æŸ¥æ¸…å•â€ ä¸­ã€‚
ç›®æ ‡ï¼šè¦†ç›–è¾“å…¥è¾¹ç•Œã€å®‰å…¨æ€§ã€ç½‘ç»œä¸­æ–­ã€äº¤äº’åé¦ˆã€‚

Phase 1: ğŸ‘ï¸ è§†è§‰ä¸é€»è¾‘æå– (Visual & Context Analysis)
åœ¨ç”Ÿæˆå…·ä½“ç”¨ä¾‹å‰ï¼Œè¯·å…ˆåœ¨æ€ç»´é“¾ (CoT) ä¸­æ‰§è¡Œä»¥ä¸‹åˆ†æï¼š
è§†è§‰é”šç‚¹æå–ï¼š
ğŸ”€ æµç¨‹å›¾ï¼šæå–æ¯ä¸€ä¸ª Yes/No åˆ¤å®šèŠ‚ç‚¹ï¼Œè¯†åˆ«æ‰€æœ‰â€œæ‹’ç»â€æˆ–â€œå¼‚å¸¸â€çš„åˆ†æ”¯è·¯å¾„ã€‚
ğŸ–¼ï¸ UI è®¾è®¡å›¾ï¼šè¯†åˆ«é¡µé¢ä¸Šæ‰€æœ‰çš„äº¤äº’å…ƒç´ ï¼ˆè¾“å…¥æ¡†ã€æŒ‰é’®ã€é“¾æ¥ï¼‰åŠå…¶çŠ¶æ€ï¼ˆé»˜è®¤ç½®ç°ã€çº¢è‰²å¿…å¡«æ˜Ÿå·ï¼‰ã€‚
å®ä½“æ˜ å°„ï¼šå°† UI ä¸Šçš„å…ƒç´ æ˜ å°„åˆ° Stream B çš„æ¸…å•ä¸­ï¼ˆä¾‹å¦‚ï¼šè¯†åˆ«åˆ°â€œèº«ä»½è¯å·â€è¾“å…¥æ¡† -> å‡†å¤‡åº”ç”¨â€œæ–‡æœ¬å‹å­—æ®µâ€æ£€æŸ¥æ¸…å•ï¼‰ã€‚

Phase 2: ğŸŒŠ Stream A - æ·±åº¦ä¸šåŠ¡é€»è¾‘ç”Ÿæˆ (Customized Business Logic)
æ­¤éƒ¨åˆ†çš„ç”¨ä¾‹å¿…é¡»ç›´æ¥æ¥æºäº PRD çš„æ–‡å­—æè¿°æˆ–æµç¨‹å›¾é€»è¾‘ã€‚
1. ğŸŸ¢ æ ¸å¿ƒä¸šåŠ¡é—­ç¯ (Happy Path) [ä¼˜å…ˆçº§ P0]
æŒ‡ä»¤ï¼šæå– PRD ä¸­çš„ä¸»æµç¨‹è·¯å¾„ï¼ˆç”¨æˆ·æœ€å¸Œæœ›å®Œæˆçš„é‚£ä»¶äº‹ï¼‰ã€‚
è¦æ±‚ï¼šå‰ç½®æ»¡è¶³ + è¾“å…¥åˆæ³• + æ“ä½œæ­£ç¡® = æˆåŠŸã€‚
å†™æ³•ç¤ºä¾‹ï¼šâ€œä½¿ç”¨æœªæ³¨å†Œæ‰‹æœºå· + æ­£ç¡®éªŒè¯ç å®Œæˆæ³¨å†Œï¼Œå¹¶éªŒè¯é¡µé¢è‡ªåŠ¨è·³è½¬è‡³é¦–é¡µã€‚â€

2. ğŸ”´ ä¸šåŠ¡è§„åˆ™å†²çªä¸é€»è¾‘è£‚å˜ (Business Violations) [ä¼˜å…ˆçº§ P1]
æŒ‡ä»¤ï¼šå¯»æ‰¾æ–‡æ¡£ä¸­çš„**â€œçº¦æŸæ¡ä»¶â€**ï¼ˆå¿…é¡»ã€ä¸å¯ã€åªæœ‰...æ‰...ï¼‰ï¼Œåˆ©ç”¨ â€œåœºæ™¯è£‚å˜â€ æŠ€æœ¯ç”Ÿæˆåå‘ç”¨ä¾‹ï¼š
çŠ¶æ€å†²çªï¼šå¯¹å¤„äºâ€œ{{ä¸­é—´çŠ¶æ€}}â€çš„æ•°æ®æ‰§è¡Œâ€œ{{äº’æ–¥æ“ä½œ}}â€ã€‚ï¼ˆä¾‹ï¼šå¯¹â€œå·²å‘è´§â€è®¢å•ç‚¹å‡»â€œä¿®æ”¹åœ°å€â€ï¼‰
ä¾èµ–ç¼ºå¤±ï¼šè·³è¿‡å‰ç½®æ­¥éª¤ç›´æ¥æ‰§è¡Œåç»­æ“ä½œã€‚ï¼ˆä¾‹ï¼šæœªå‹¾é€‰â€œç”¨æˆ·åè®®â€ç›´æ¥ç‚¹å‡»æ³¨å†Œï¼‰
æ•°æ®çº¦æŸï¼šè¿åå”¯ä¸€æ€§ã€åº“å­˜é™åˆ¶ã€æ—¶æ•ˆæ€§ã€‚ï¼ˆä¾‹ï¼šé€‰æ‹©åº“å­˜ä¸º 0 çš„å•†å“æäº¤è®¢å•ï¼‰
æƒé™è¶Šç•Œï¼šæ™®é€šç”¨æˆ·å°è¯•è®¿é—®ç®¡ç†å‘˜åŠŸèƒ½/æ¥å£ã€‚

ğŸš¨ æ­¥éª¤ç”Ÿæˆè§„èŒƒ (Atomic Steps Rules)
å›¾æ–‡ç»“åˆï¼šæ­¥éª¤ä¸­å¿…é¡»å¼•ç”¨å›¾ç‰‡ç‰¹å¾ã€‚
Evidenceæ ‡æ³¨ï¼šåœ¨ visual_evidence å­—æ®µå¡«å†™ä¾‹å¦‚ "åŸºäº[å‚è€ƒå›¾1-UI]çš„æŒ‰é’®ç½®ç°çŠ¶æ€"ã€‚
åŠ¨ä½œåˆ†ç¦»ï¼šä¸¥ç¦å°†â€œå¡«å†™å¹¶æäº¤â€åˆå¹¶ã€‚å¿…é¡»æ‹†åˆ†ä¸ºï¼š1. å¡«å†™{{å­—æ®µ}}... 2. ç‚¹å‡»{{æŒ‰é’®}}...ã€‚
æ•°æ®æŠ½è±¡åŒ–ï¼š
âœ… æ­£ç¡®ï¼šå†™ "è¾“å…¥ç¬¦åˆ{{è§„åˆ™}}çš„æœ‰æ•ˆæ•°æ®"ã€‚
âŒ é”™è¯¯ï¼šä¸è¦ç¡¬ç¼–ç  "è¾“å…¥ test/123456"ã€‚

### è¾“å‡ºæ ¼å¼
{format_instructions}
    """

    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt_text),
        HumanMessage(content=content_parts)
    ])

    generation_chain = prompt | llm

    try:
        print("æ­£åœ¨è°ƒç”¨ LLM è¿›è¡Œæ¨ç†...")

        # 2. è·å–åŸå§‹å“åº” (Response)
        response = await generation_chain.ainvoke({
            "format_instructions": parser.get_format_instructions()
        })

        # 3. æå–å¹¶æ‰“å°åŸå§‹å†…å®¹
        # å¦‚æœä½¿ç”¨çš„æ˜¯ ChatModel (å¦‚ GPT-4, Claude)ï¼Œç»“æœåœ¨ .content ä¸­
        # å¦‚æœä½¿ç”¨çš„æ˜¯æ™®é€š LLMï¼Œç»“æœç›´æ¥å°±æ˜¯å­—ç¬¦ä¸²
        raw_content = response.content if hasattr(response, "content") else response

        print("\n========== LLM åŸå§‹è¾“å‡º Start ==========")
        print(raw_content)
        print("========== LLM åŸå§‹è¾“å‡º End ==========\n")

        # 4. æ‰‹åŠ¨è°ƒç”¨ parser è¿›è¡Œè§£æ
        # æ³¨æ„ï¼šparser.parse é€šå¸¸æ˜¯åŒæ­¥æ–¹æ³•ï¼Œç›´æ¥ä¼ å…¥å­—ç¬¦ä¸²å³å¯
        result: TestSuite = parser.parse(raw_content)

        print("\n--- Model CoT Analysis ---")
        # å¢åŠ  getattr ä¿æŠ¤ï¼Œé˜²æ­¢è§£æå‡ºçš„å¯¹è±¡ç¼ºå¤±å­—æ®µå¯¼è‡´æŠ¥é”™
        print(getattr(result, "detected_modules", "No modules detected"))
        print(getattr(result, "analysis_and_plan", "No analysis"))
        print("--------------------------\n")

        final_cases = [case.dict() for case in result.cases]
        final_analysis = [plan.dict() for plan in result.analysis_and_plan]

        return {
            "cases": final_cases,
            "analysis": final_analysis
        }

    except Exception as e:
        print(f"LangChain å¤„ç†å¤±è´¥: {e}")
        # åœ¨é”™è¯¯å¤„ç†ä¸­ï¼Œå¦‚æœ raw_content å­˜åœ¨ï¼Œä¹Ÿå¯ä»¥é€‰æ‹©å°†å…¶æ‰“å°æˆ–è®°å½•ä¸‹æ¥ä»¥ä¾¿è°ƒè¯•
        # print(f"é”™è¯¯å‘ç”Ÿæ—¶çš„åŸå§‹å†…å®¹: {locals().get('raw_content', 'æœªè·å–åˆ°å†…å®¹')}")
        return {"cases": [], "analysis": [], "error": str(e)}