from typing import Optional
import uvicorn
import traceback
import json
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from prd_parser import FeishuDocParser
from file_parser import parse_uploaded_file  # ã€æ–°å¢å¯¼å…¥ã€‘
from model import get_llm, build_content_parts, step_1_analyze_and_plan, step_2_generate_cases
from db import save_result, get_result_by_key, init_db

try:
    init_db()
except Exception as e:
    print(f"Database initialization failed: {e}")

app = FastAPI(title="åŸºäºLLMçš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆ")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


class CaseSaveRequest(BaseModel):
    final_json: dict = Field(..., description="æœ€ç»ˆç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹å’Œåˆ†æçš„ JSON ç»“æ„")


async def generate_stream_process(
        input_mode: str,
        doc_url: str,
        raw_content: str,
        app_id: str,
        app_secret: str,
        uploaded_file: UploadFile
):
    try:
        parsed_data = []

        if input_mode == 'link':
            yield json.dumps({"type": "log", "message": "æ­£åœ¨è§£æé£ä¹¦æ–‡æ¡£..."}) + "\n"
            if not doc_url:
                raise ValueError("è¯·æä¾›é£ä¹¦æ–‡æ¡£é“¾æ¥")
            if not app_id or not app_secret:
                raise ValueError("è¯·æä¾›é£ä¹¦ App ID å’Œ App Secret")

            parser = FeishuDocParser(app_id, app_secret)
            parsed_data = parser.parse(doc_url)

        elif input_mode == 'text':
            yield json.dumps({"type": "log", "message": "æ­£åœ¨è§£æç²˜è´´çš„æ–‡æœ¬å†…å®¹..."}) + "\n"
            if not raw_content:
                raise ValueError("è¯·ç²˜è´´ PRD æ–‡æœ¬å†…å®¹")

            parsed_data = FeishuDocParser.parse_text(raw_content)

        elif input_mode == 'file':
            yield json.dumps({"type": "log", "message": f"æ­£åœ¨è§£æä¸Šä¼ çš„æ–‡ä»¶: {uploaded_file.filename}..."}) + "\n"
            if not uploaded_file:
                raise ValueError("æœªæ¥æ”¶åˆ°ä¸Šä¼ çš„æ–‡ä»¶")

            text_content = await parse_uploaded_file(uploaded_file)

            if not text_content:
                raise ValueError("æ–‡ä»¶å†…å®¹ä¸ºç©ºæˆ–æ— æ³•æå–")

            # å°†æå–çš„æ–‡æœ¬è½¬æ¢ä¸º LLM ç»Ÿä¸€æ ¼å¼
            parsed_data = FeishuDocParser.parse_text(text_content)

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å…¥æ¨¡å¼: {input_mode}")

        if not parsed_data:
            yield json.dumps({"type": "error", "message": "è§£æå†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥è¾“å…¥"}) + "\n"
            return


        image_map = {}
        img_count = 0
        for node in parsed_data:
            if node['type'] == 'image':
                img_count += 1
                image_map[str(img_count)] = node['base64']


        yield json.dumps({"type": "images", "data": image_map}) + "\n"

        # --- é˜¶æ®µ 2: AI åˆ†æ (ç”Ÿæˆå¯¼å›¾) ---
        yield json.dumps({"type": "log", "message": "æ­£åœ¨è¿›è¡Œ AI æ·±åº¦åˆ†æä¸ç­–ç•¥åˆ¶å®š..."}) + "\n"

        llm = get_llm()
        content_parts = build_content_parts(parsed_data)

        # æ‰§è¡Œ Step 1
        plan_result = await step_1_analyze_and_plan(llm, content_parts)

        final_analysis = [
            p.model_dump() if hasattr(p, 'model_dump') else p.dict()
            for p in plan_result.analysis_and_plan
        ]

        yield json.dumps({
            "type": "analysis",
            "data": final_analysis
        }) + "\n"

        yield json.dumps({"type": "log", "message": "ç­–ç•¥å·²ç¡®è®¤ï¼Œæ­£åœ¨ç”Ÿæˆè¯¦ç»†æµ‹è¯•ç”¨ä¾‹..."}) + "\n"

        # æ‰§è¡Œ Step 2
        case_result = await step_2_generate_cases(llm, content_parts, plan_result)

        final_cases = [
            c.model_dump() if hasattr(c, 'model_dump') else c.dict()
            for c in case_result.cases
        ]

        yield json.dumps({
            "type": "cases",
            "data": final_cases
        }) + "\n"

        yield json.dumps({"type": "done", "message": "ç”Ÿæˆå®Œæ¯•"}) + "\n"

    except Exception as e:
        error_msg = traceback.format_exc()
        print(f"ğŸ”¥ æµç¨‹å¼‚å¸¸: {e}")
        yield json.dumps({"type": "error", "message": str(e)}) + "\n"


@app.post("/generate_from_feishu")
async def generate_from_feishu(
    input_mode: str = Form("link"),
    doc_url: str = Form(None),
    raw_content: str = Form(None),
    app_id: str = Form(None),
    app_secret: str = Form(None),
    uploaded_file: Optional[UploadFile] = File(None)
):
    print(f"æ”¶åˆ°è¯·æ±‚ï¼Œæ¨¡å¼: {input_mode}")
    return StreamingResponse(
        generate_stream_process(
            input_mode, doc_url, raw_content, app_id, app_secret, uploaded_file
        ),
        media_type="application/x-ndjson"
    )


@app.post("/save_result")
async def save_case_result(req: CaseSaveRequest):
    try:
        # url è¿”å› '/?key={unique_key}'
        unique_key = save_result(req.final_json)
        return {"key": unique_key, "url": f"/?key={unique_key}"}
    except Exception as e:
        print(f"ğŸ”¥ ä¿å­˜å¼‚å¸¸: {e}")
        return {"message": "ä¿å­˜å¤±è´¥", "error": str(e)}, 500


@app.get("/load/{key}")
async def load_case_result(key: str):
    result = get_result_by_key(key)
    if result:
        return result
    else:
        return {"message": "æœªæ‰¾åˆ°å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹ç»“æœ"}, 404


app.mount("/static", StaticFiles(directory="."), name="static")


@app.get("/", response_class=HTMLResponse)
async def serve_frontend():
    try:
        with open("test_case_web.html", "r", encoding="utf-8") as f:
            html_content = f.read()
        return HTMLResponse(content=html_content)
    except FileNotFoundError:
        return HTMLResponse(content="<h1>Error: test_case_web.html not found.</h1>", status_code=404)


if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)