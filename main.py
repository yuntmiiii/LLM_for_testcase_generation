from starlette.middleware.cors import CORSMiddleware

import os
import uvicorn
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List

from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser

import prompts

load_dotenv()

app = FastAPI(title="è‡ªåŠ¨æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæœåŠ¡")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰åŸŸåï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®æŒ‡å®šå…·ä½“åŸŸåï¼Œå¦‚ "http://localhost:3000"ï¼‰
    allow_credentials=True,
    allow_methods=["*"],  # å…è®¸æ‰€æœ‰ HTTP æ–¹æ³•ï¼ˆåŒ…æ‹¬ OPTIONSã€POSTï¼‰
    allow_headers=["*"],  # å…è®¸æ‰€æœ‰è¯·æ±‚å¤´
)

class PRDRequest(BaseModel):
    content: str = Field(..., description="äº§å“éœ€æ±‚æ–‡æ¡£(PRD)çš„æ–‡æœ¬å†…å®¹")

class TestCase(BaseModel):
    module: str = Field(description="åŠŸèƒ½æ¨¡å—åç§°")
    title: str = Field(description="ç”¨ä¾‹æ ‡é¢˜")
    pre_condition: str = Field(description="å‰ç½®æ¡ä»¶")
    steps: List[str] = Field(description="æµ‹è¯•æ­¥éª¤åˆ—è¡¨")
    expected_result: str = Field(description="é¢„æœŸç»“æœ")

# å®šä¹‰æœ€ç»ˆè¿”å›ç»™å‰ç«¯çš„ç»“æ„ (åŒ…å«ç”¨ä¾‹åˆ—è¡¨)
class TestCasesOutput(BaseModel):
    cases: List[TestCase]

@app.post("/generate")
async def generate_cases(req: PRDRequest):
    if not os.getenv("OPENAI_API_KEY"):
        raise HTTPException(status_code=500, detail="æœåŠ¡å™¨æœªé…ç½® OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶")
    api_key = os.getenv("ARK_API_KEY")
    model_endpoint = 'ep-20251120150050-5x4qz'
    try:
        llm = ChatOpenAI(
            api_key=api_key,
            base_url="https://ark.cn-beijing.volces.com/api/v3",
            model=model_endpoint,
            temperature=0,
            timeout=300,
            max_retries=1,
            http_client=None 
        )
        parser = JsonOutputParser(pydantic_object=TestCasesOutput)

        prompt = ChatPromptTemplate.from_messages([
            ("system", prompts.SYSTEM_PROMPT),
            ("user", prompts.USER_TEMPLATE)
        ])

        chain = prompt | llm | parser

        result = await chain.ainvoke({
            "format_instructions": parser.get_format_instructions(),
            "prd_text": req.content.strip()
        })
        print(result)
        return {"status": "success", "data": result}

    except HTTPException as e:
        raise e
    except Exception as e:
        error_msg = f"ç”¨ä¾‹ç”Ÿæˆå¤±è´¥ï¼š{str(e)}"
        print(f"ç”Ÿæˆå‡ºé”™: {error_msg}")
        return {"status": "error", "message": error_msg}

if __name__ == "__main__":
    print("ğŸš€ æµ‹è¯•ç”¨ä¾‹ç”ŸæˆæœåŠ¡æ­£åœ¨å¯åŠ¨...")
    print("ğŸ“¡ ç›‘å¬åœ°å€: http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)